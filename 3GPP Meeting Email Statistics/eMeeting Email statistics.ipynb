{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input information\n",
    "# NOTE: the file name is just a file the author used for testing, the file is not included in the repository\n",
    "\n",
    "# To export to html, just use (e.g. in Anaconda prompt). Note that only cell output will be shown\n",
    "# jupyter nbconvert \"eMeeting Email statistics.ipynb\" --to html --no-input --output SA2-XXX\n",
    "\n",
    "# SA2-151E\n",
    "meeting = {\n",
    "    'file':  \"SA2-151E/2022.05.20 173758 email summary.csv\",\n",
    "    'title': \"SA2-151E\",\n",
    "    'dates': ['2022-05-15 19:00','2022-05-20 19:00'],\n",
    "    'tdocs_cache': 'SA2-151E/TDocsByAgenda_TSGS2_151E_Electronic_2022-05_f4fc704f4d4a7fd4b17e3fc06f18c30a.pickle',\n",
    "    'revisions_file': 'SA2-151E/Revisions.htm'\n",
    "}\n",
    "\n",
    "# SA2-150E\n",
    "# meeting = {\n",
    "#     'file':  \"SA2-150E/2022.04.14 154209 email summary.csv\",\n",
    "#     'title': \"SA2-150E\",\n",
    "#     'dates': ['2022-04-05 19:00','2022-04-13 19:00'],\n",
    "#     'tdocs_cache': 'SA2-150E/TDocsByAgenda_TSGS2_150E_Electronic_2022-04_f47b95529dbe75054defc124e16af002.pickle',\n",
    "#     'revisions_file': 'SA2-150E/Revisions.htm'\n",
    "# }\n",
    "\n",
    "# SA2-149E\n",
    "# meeting = {\n",
    "#     'file':  \"SA2-149E/2022.03.01 183210 email summary.csv\",\n",
    "#     'title': \"SA2-149E\",\n",
    "#     'dates': ['2022-02-13 00:00','2022-02-25 19:00'],\n",
    "#     'tdocs_cache': 'SA2-149E/TDocsByAgenda_TSGS2_149E_Electronic_2022-02_387b3b94cc2838f00431543a09d1e80f.pickle',\n",
    "#     'revisions_file': 'SA2-149E/Revisions.htm'\n",
    "# }\n",
    "\n",
    "# SA2-148E\n",
    "# meeting = {\n",
    "#     'file':  \"SA2-148E/2021.11.24 133044 email summary.csv\",\n",
    "#     'title': \"SA2-148E\",\n",
    "#     'dates': ['2021-11-14 00:00','2021-11-22 19:00'],\n",
    "#     'tdocs_cache': 'SA2-148E/TDocsByAgenda_TSGS2_148E_Electronic_2021-11_4a55300eacb5103dd52141f002054e00.pickle',\n",
    "#     'revisions_file': 'SA2-148E/Revisions.htm'\n",
    "# }\n",
    "\n",
    "# SA2-147E\n",
    "# meeting = {\n",
    "#     'file':  \"SA2-147E/2021.11.24 133606 email summary.csv\",\n",
    "#     'title': \"SA2-147E\",\n",
    "#     'dates': ['2021-10-17 00:00','2021-10-22 19:00'],\n",
    "#     'tdocs_cache': 'SA2-147E/TDocsByAgenda_TSGS2_147E_Electronic_2021-10_ed705a2623f7a9c3bae4ba986b8b39f6.pickle',\n",
    "#     'revisions_file': 'SA2-147E/Revisions.htm'\n",
    "# }\n",
    "\n",
    "# SA2-146E\n",
    "# meeting = {\n",
    "#     'file':  \"SA2-146E/2021.08.30 124049 email summary.csv\",\n",
    "#     'title': \"SA2-146E\",\n",
    "#     'dates': ['2021-08-15 00:00','2021-08-27 19:00'],\n",
    "#     'tdocs_cache': 'SA2-146E/TDocsByAgenda_TSGS2_146E_Electronic_2021-08_2bf6392e473b9c926b8da7687812cf88.pickle',\n",
    "#     'revisions_file': 'SA2-146E/Revisions.htm'\n",
    "# }\n",
    "\n",
    "# SA2-145E\n",
    "# meeting = {\n",
    "#     'file':  \"SA2-145E/2021.06.01 122806 email summary.csv\",\n",
    "#     'title': \"SA2-145E\",\n",
    "#     'dates': ['2021-05-17 00:00','2021-05-28 19:00'],\n",
    "#     'tdocs_cache': 'SA2-145E/TDocsByAgenda_TSGS2_145E_Electronic_2021-05_3e0c019a905d4ad4f07838ec4666e52a.pickle',\n",
    "#     'revisions_file': 'SA2-145E/Revisions.htm'\n",
    "# }\n",
    "\n",
    "# SA2-144E\n",
    "# meeting = {\n",
    "#     'file':  \"2021.04.16 155958 email summary.csv\",\n",
    "#     'title': \"SA2-144E\",\n",
    "#     'dates': ['2021-04-12 00:00','2021-04-16 19:00'],\n",
    "#     'tdocs_cache': 'TDocsByAgenda_TSGS2_144E_Electronic_4be02c473112d562e8bdfcca738a39c1.pickle',\n",
    "#     'revisions_file': '2021.04.16 TSGS2_144E_Electronic_INBOX_Revisions.html'\n",
    "# }\n",
    "\n",
    "# SA2-142E\n",
    "# meeting = {\n",
    "#     'file':  \"2020.11.26 151915 email summary.csv\",\n",
    "#     'title': \"SA2-142E\",\n",
    "#     'dates': ['2020-11-15 00:00','2020-11-25 19:00'],\n",
    "#     'tdocs_cache': 'TDocsByAgenda_TSGS2_142e_Electronic_2dc7ed471f1850908a9fee9e91e0f57b.pickle',\n",
    "#     'revisions_file': '2020.11.23 Directory Listing _ftp_tsg_sa_WG2_Arch_TSGS2_142e_Electronic_INBOX_Revisions.html'\n",
    "# }\n",
    "\n",
    "# SA2-141E\n",
    "# meeting = {\n",
    "#     'file':  \"2020.10.30 225939 email summary.csv\",\n",
    "#     'title': \"SA2-141E\",\n",
    "#     'dates': ['2020-10-12 00:00','2020-10-23 19:00'],\n",
    "#     'tdocs_cache': 'TDocsByAgenda_TSGS2_141e_Electronic_0dd5f7de5d57bb0303cbbc6000a39c68.pickle'\n",
    "# }\n",
    "\n",
    "# SA2-140E\n",
    "# meeting = {\n",
    "#     'file':  \"2020.09.02 090903 email summary.csv\",\n",
    "#     'title': \"SA2-140E\",\n",
    "#     'dates': ['2020-08-19 12:00','2020-08-31 22:00'],\n",
    "#     'tdocs_cache': 'TDocsByAgenda_TSGS2_140e_Electronic_376bc93cdb21add4d0c7abe101f8f232.pickle'\n",
    "# }\n",
    "\n",
    "# SA2-139E Ph1+Ph2\n",
    "# meeting = {\n",
    "#     'file':  \"2020.06.15 073045 email summary.csv\",\n",
    "#     'title': \"SA2-139E Ph1+Ph2\",\n",
    "#     'dates': ['2020-05-31 12:00','2020-06-12 19:00']\n",
    "# }\n",
    "\n",
    "# SA2-138E\n",
    "#meeting = {\n",
    "#    'file':  \"2020.04.24 153334 email summary.csv\",\n",
    "#    'title': \"SA2-138E\",\n",
    "#    'dates': ['2020-04-19 12:00','2020-04-24 19:00']\n",
    "#}\n",
    "\n",
    "# SA2-137E\n",
    "# meeting = {\n",
    "#    'file':  \"2020.03.02 080314 email summary.csv\",\n",
    "#    'title': \"SA2-137E\",\n",
    "#    'dates': ['2020-02-23 12:00','2020-02-28 19:00'],\n",
    "#    'tdocs_cache': 'TDocsByAgenda_TSGS2_137e_Electronic_f758bcb52ead1c245c3797d880ae986c.pickle'\n",
    "# }\n",
    "\n",
    "ranking_length = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You will need pandas/numpy to run the first part of the script. Then plotly for the second part. You can install plotly via pip (pip install plotly)\n",
    "# If the PNG export is not working, most probably orca is not installed. You can install it by executing in the Anaconda cmd: conda install -c plotly plotly-orca\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import re\n",
    "import pickle\n",
    "import html2text\n",
    "import traceback\n",
    "from IPython.display import Markdown as md\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "import plotly.graph_objects as go\n",
    "import os\n",
    "import os.path\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create variables\n",
    "email_dump    = meeting[\"file\"]\n",
    "title         = meeting[\"title\"]\n",
    "meeting_dates = meeting[\"dates\"]\n",
    "\n",
    "# Create DataFrame for analysis\n",
    "df = pd.read_csv(\n",
    "    email_dump,\n",
    "    index_col=0,\n",
    "    dtype=object)\n",
    "df['date']    = pd.to_datetime(df['date'], errors='coerce')\n",
    "\n",
    "# Filter out NaTs (datetime conversion errors)\n",
    "conversion_oks = pd.notnull(df['date'])\n",
    "df = df[conversion_oks]\n",
    "\n",
    "df['day']     = df['date'].dt.floor('d')\n",
    "df['hour']    = df['date'].dt.floor('h')\n",
    "\n",
    "def parse_email_company(x):\n",
    "    try:\n",
    "        email_address_split = x.split('@')\n",
    "        company_domain      = email_address_split[-1]\n",
    "        company_name_split  = company_domain.split('.')\n",
    "        \n",
    "        if 'COM.CN' in x or 'COM.TR' in x or 'com.cn' in x or 'com.tr' in x:\n",
    "            company_name = company_name_split[0]\n",
    "        else:\n",
    "            company_name = company_name_split[-2]\n",
    "        \n",
    "        if len(company_name) <= 4:\n",
    "            company_name = company_name.upper()\n",
    "        else:\n",
    "            company_name = company_name.capitalize()\n",
    "            \n",
    "        if company_name=='COM':\n",
    "            print(x)\n",
    "            \n",
    "        # Some substitutions for big companies that show in rankings\n",
    "        if company_name=='Ztetx':\n",
    "            company_name = 'ZTE'\n",
    "        elif company_name=='Nokia-sbell' or company_name=='Nokia-bell-labs':\n",
    "            company_name = 'Nokia'\n",
    "        elif company_name=='Docomolab-euro':\n",
    "            company_name = 'NTT Docomo'\n",
    "        elif company_name=='Magenta':\n",
    "            company_name = 'Deutsche Telekom'\n",
    "            \n",
    "        return company_name\n",
    "    except:\n",
    "        # print('Error parsing email. Sender address: {0}'.format(x))\n",
    "        return ''\n",
    "df['company'] = df['sender address'].apply(parse_email_company)\n",
    "\n",
    "# display(df.company.unique())\n",
    "\n",
    "# Dataframe grouping\n",
    "email_count_per_ai   = df.groupby('ai').count()\n",
    "email_count_per_day  = df.groupby('day').count()\n",
    "email_count_per_hour = df.groupby('hour').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-process DataFrame\n",
    "max_rows = pd.options.display.max_rows\n",
    "pd.options.display.max_rows = None\n",
    "\n",
    "# Ranking based on emails per company\n",
    "emails_count = df.groupby('sender name').count().sort_values(by='date', ascending=False)\n",
    "# See https://stackoverflow.com/questions/49574817/fill-a-new-pandas-column-with-row-numbers\n",
    "emails_count['ranking'] = np.arange(len(emails_count)) + 1\n",
    "emails_count['emails'] = emails_count['date']\n",
    "\n",
    "emails_count_company = df.groupby('company').count().sort_values(by='date', ascending=False)\n",
    "\n",
    "# See https://stackoverflow.com/questions/49574817/fill-a-new-pandas-column-with-row-numbers\n",
    "emails_count_company['ranking'] = np.arange(len(emails_count_company)) + 1\n",
    "emails_count_company['emails'] = emails_count_company['date']\n",
    "\n",
    "# Ranking based on emails per delegate\n",
    "active_delegate_list = pd.DataFrame()\n",
    "grouped_df = df.groupby(['company', 'sender name']).count()\n",
    "active_delegate_list['company']       = grouped_df.index.get_level_values(0).copy()\n",
    "active_delegate_list['delegate name'] = grouped_df.index.get_level_values(1).copy()\n",
    "# display(active_delegate_list)\n",
    "active_delegate_count = active_delegate_list.groupby('company').count()\n",
    "# display(active_delegate_count)\n",
    "# display(emails_count_company)\n",
    "\n",
    "# Taking into account number of delegates per company\n",
    "emails_per_active_delegate_count = emails_count_company['emails']/active_delegate_count['delegate name']\n",
    "emails_count_company['emails/active delegate'] = emails_per_active_delegate_count\n",
    "emails_count_company['active delegates'] = active_delegate_count['delegate name']\n",
    "emails_count_company['total emails'] = emails_count_company['emails']\n",
    "emails_count_company_resort = emails_count_company.sort_values(by='emails/active delegate', ascending=False)\n",
    "emails_count_company_resort['ranking'] = np.arange(len(emails_count_company)) + 1\n",
    "# display(emails_count_company_resort[['ranking', 'emails/active delegate', 'active delegates', 'total emails']].iloc[0:20,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_emails = email_count_per_ai['date'].sum()\n",
    "total_delegates = len(emails_count.index)\n",
    "total_companies = len(emails_count_company.index)\n",
    "display(md(\"Total emails: {0}\".format(total_emails)))\n",
    "display(md(\"Number of active delegates: {0}\".format(total_delegates)))\n",
    "display(md(\"Number of active companies: {0}\".format(total_companies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Where to save plots\n",
    "plot_folders = meeting['title']\n",
    "plot_folder_html = os.path.join(plot_folders, 'html')\n",
    "plot_folder_png  = os.path.join(plot_folders, 'png')\n",
    "\n",
    "if not os.path.exists(plot_folders):\n",
    "    os.mkdir(plot_folders)\n",
    "if not os.path.exists(plot_folder_html):\n",
    "    os.mkdir(plot_folder_html)\n",
    "if not os.path.exists(plot_folder_png):\n",
    "    os.mkdir(plot_folder_png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "company_sizes_list_length = 10\n",
    "# display(emails_count_company.sort_values(by=['active delegates', 'total emails'], ascending=False).iloc[0:(company_sizes_list_length+1),:].loc[:,['active delegates', 'total emails']])\n",
    "\n",
    "pie_threshold = 3\n",
    "emails_count_company_percent = emails_count_company.sort_values(by=['total emails'], ascending=False).loc[:,['active delegates', 'total emails']]\n",
    "emails_count_company_percent['delegation percent'] = emails_count_company_percent['active delegates'] / total_delegates\n",
    "emails_count_company_percent = emails_count_company_percent.loc[emails_count_company_percent['active delegates'] >= pie_threshold,:]\n",
    "\n",
    "extra_row = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'Others (<{0} delegates)'.format(pie_threshold): [\n",
    "            total_delegates - emails_count_company_percent['active delegates'].sum(),\n",
    "            total_emails - emails_count_company_percent['total emails'].sum(),\n",
    "            1 - emails_count_company_percent['delegation percent'].sum()\n",
    "        ]\n",
    "    }, \n",
    "    orient='index',\n",
    "    columns=['active delegates', 'total emails', 'delegation percent'])\n",
    "\n",
    "\n",
    "emails_count_company_percent = pd.concat([emails_count_company_percent, extra_row])\n",
    "# display(emails_count_company_percent)\n",
    "\n",
    "fig = px.pie(\n",
    "    emails_count_company_percent, \n",
    "    title='Delegation distribution (total {0} active delegates)'.format(total_delegates),\n",
    "    names=emails_count_company_percent.index,\n",
    "    values='active delegates',\n",
    "    labels={\n",
    "        'index': 'Company'\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig_title = \"{0} {1}\".format(title, \"Delegate distribution\")\n",
    "\n",
    "fig.write_html(os.path.join(plot_folder_html,  fig_title + \".html\"))\n",
    "# fig.write_image(os.path.join(plot_folder_png, fig_title + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_threshold = 0.02\n",
    "company_ranking_per_emails = emails_count_company.sort_values(by=['total emails'], ascending=False).loc[:,['active delegates', 'total emails']]\n",
    "company_ranking_per_emails['email percent'] = company_ranking_per_emails['total emails'] / total_emails\n",
    "company_ranking_per_emails = company_ranking_per_emails.loc[company_ranking_per_emails['email percent'] > pie_threshold,:]\n",
    "\n",
    "extra_row = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'Others (<{0}%)'.format(pie_threshold*100): [\n",
    "            total_delegates - company_ranking_per_emails['active delegates'].sum(),\n",
    "            total_emails - company_ranking_per_emails['total emails'].sum(),\n",
    "            1 - company_ranking_per_emails['email percent'].sum()\n",
    "        ]\n",
    "    }, \n",
    "    orient='index',\n",
    "    columns=['active delegates', 'total emails', 'email percent'])\n",
    "\n",
    "company_ranking_per_emails = pd.concat([company_ranking_per_emails, extra_row])\n",
    "# display(company_ranking_per_emails)\n",
    "\n",
    "fig = px.pie(\n",
    "    company_ranking_per_emails, \n",
    "    title='Biggest email contributors (companies)',\n",
    "    names=company_ranking_per_emails.index,\n",
    "    values='total emails',\n",
    "    labels={\n",
    "        'index': 'Company'\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig_title = \"{0} {1}\".format(title, \"Emails per company\")\n",
    "fig.write_html(os.path.join(plot_folder_html,  fig_title + \".html\"))\n",
    "# fig.write_image(os.path.join(plot_folder_png, fig_title + \".png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emails/delegate\n",
    "Not sure whether it is good to be in this list..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(emails_count[['ranking', 'emails']].iloc[0:(ranking_length+1),:])\n",
    "pd.options.display.max_rows = 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emails per AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = go.Bar(\n",
    "    x=email_count_per_ai.index, \n",
    "    y=email_count_per_ai['date'])\n",
    "layout = go.Layout(\n",
    "    xaxis= {'type': 'category'})\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "fig.update_xaxes(title_text='AI')\n",
    "fig.update_yaxes(title_text='Emails/AI')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig_title = \"{0} {1}\".format(title, \"Emails per AI\")\n",
    "fig.write_html(os.path.join(plot_folder_html, fig_title + \".html\"))\n",
    "# fig.write_image(os.path.join(plot_folder_png, fig_title + \".png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emails per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = go.Bar(\n",
    "    x=email_count_per_day.index, \n",
    "    y=email_count_per_day['date'])\n",
    "layout = go.Layout(\n",
    "    xaxis_tickformat = '%d.%m',\n",
    "    xaxis_range = meeting_dates,\n",
    "    xaxis = { 'dtick': 1000*3600*24 })\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "fig.update_xaxes(title_text='Date')\n",
    "fig.update_yaxes(title_text='Emails/day')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig_title = \"{0} {1}\".format(title, \"Emails per day\")\n",
    "fig.write_html(os.path.join(plot_folder_html,  fig_title + \".html\"))\n",
    "# fig.write_image(os.path.join(plot_folder_png, fig_title + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data source for emails/day per AI\n",
    "email_count_per_day_and_ai = df.groupby(['ai', 'day']).count()\n",
    "\n",
    "ai_plot = {}\n",
    "ais = df.ai.unique()\n",
    "for ai in ais:\n",
    "    ai_plot[ai] = email_count_per_day_and_ai[email_count_per_day_and_ai.index.isin([ai], level=0)]['date']\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis_tickformat = '%d.%m',\n",
    "    xaxis_range = meeting_dates,\n",
    "    xaxis = { 'dtick': 1000*3600*24 } )\n",
    "\n",
    "fig = go.Figure(layout=layout)\n",
    "\n",
    "for ai in ais:\n",
    "    bar_data = ai_plot[ai]\n",
    "    bar_y = bar_data\n",
    "    bar_x = bar_data.index.get_level_values(1)\n",
    "    bar_title = ai\n",
    "    data = go.Bar(\n",
    "        x=bar_x, \n",
    "        y=bar_y,\n",
    "        name=bar_title)\n",
    "    fig.add_trace(data)\n",
    "\n",
    "fig.update_layout(barmode='relative')\n",
    "\n",
    "fig.update_xaxes(title_text='Date')\n",
    "fig.update_yaxes(title_text='Emails/day')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig_title = \"{0} {1}\".format(title, \"Emails per day and AI\")\n",
    "fig.write_html(os.path.join(plot_folder_html,  fig_title + \".html\"))\n",
    "# fig.write_image(os.path.join(plot_folder_png, fig_title + \".png\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emails per hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = go.Bar(\n",
    "    x=email_count_per_hour.index, \n",
    "    y=email_count_per_hour['date'])\n",
    "layout = go.Layout(\n",
    "    xaxis_tickformat = '%d.%m  %Hh',\n",
    "    xaxis_range = meeting_dates)\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "\n",
    "fig.update_xaxes(title_text='Date')\n",
    "fig.update_yaxes(title_text='Emails/hour')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig_title = \"{0} {1}\".format(title, \"Emails per hour\")\n",
    "fig.write_html(os.path.join(plot_folder_html,  fig_title + \".html\"))\n",
    "# fig.write_image(os.path.join(plot_folder_png, fig_title + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data source for emails/h per AI\n",
    "email_count_per_hour_and_ai = df.groupby(['ai', 'hour']).count()\n",
    "\n",
    "ai_plot = {}\n",
    "ais = df.ai.unique()\n",
    "for ai in ais:\n",
    "    ai_plot[ai] = email_count_per_hour_and_ai[email_count_per_hour_and_ai.index.isin([ai], level=0)]['date']\n",
    "\n",
    "layout = go.Layout(\n",
    "    xaxis_tickformat = '%d.%m %Hh',\n",
    "    xaxis_range = meeting_dates)\n",
    "\n",
    "fig = go.Figure(layout=layout)\n",
    "\n",
    "for ai in ais:\n",
    "    bar_data = ai_plot[ai]\n",
    "    bar_y = bar_data\n",
    "    bar_x = bar_data.index.get_level_values(1)\n",
    "    bar_title = ai\n",
    "    data = go.Bar(\n",
    "        x=bar_x, \n",
    "        y=bar_y,\n",
    "        name=bar_title)\n",
    "    fig.add_trace(data)\n",
    "\n",
    "fig.update_layout(barmode='relative')\n",
    "\n",
    "fig.update_xaxes(title_text='Date')\n",
    "fig.update_yaxes(title_text='Emails/hour')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig_title = \"{0} {1}\".format(title, \"Emails per hour and AI\")\n",
    "fig.write_html(os.path.join(plot_folder_html,  fig_title + \".html\"))\n",
    "# fig.write_image(os.path.join(plot_folder_png, fig_title + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdocs = []    \n",
    "for email_subject in df['subject']:\n",
    "    try:\n",
    "        tdocs.append(re.search(r'S2-[\\d]{7}', email_subject).group())\n",
    "    except:\n",
    "        tdocs.append('')\n",
    "        # print(email_subject)\n",
    "\n",
    "df['tdoc'] = tdocs\n",
    "# display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_per_tdoc = df.groupby(\"tdoc\")\n",
    "emails_per_tdoc = df_per_tdoc.count()\n",
    "emails_per_tdoc['Email Count'] = emails_per_tdoc['date']\n",
    "emails_per_tdoc = emails_per_tdoc.loc[:,['Email Count']]\n",
    "emails_per_tdoc.sort_values(by ='Email Count' , ascending=False, inplace=True)\n",
    "emails_per_tdoc = emails_per_tdoc.reset_index()\n",
    "\n",
    "# Not necessary if you have the pickle file\n",
    "# display(emails_per_tdoc.iloc[0:21,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross data with TdocsByAgenda data if data is available\n",
    "try:\n",
    "    with open(meeting['tdocs_cache'], 'rb') as f:\n",
    "        # Unpickle the 'data' dictionary using the highest protocol available.\n",
    "        cache         = pickle.load(f)\n",
    "        meeting_tdocs = cache['tdocs']\n",
    "        meeting_tdocs_original = meeting_tdocs\n",
    "        contributor_columns = cache['contributor_columns']\n",
    "        others_cosigners    = cache['others_cosigners']\n",
    "        # Same order and TDocs as the ones in the emails\n",
    "        meeting_tdocs = meeting_tdocs.reindex(index=list(emails_per_tdoc['tdoc']),columns=['AI', 'Title', 'Source'])\n",
    "        # display(meeting_tdocs)\n",
    "        # Need to convert to list. If not you get a list of NaNs because Pandas will try to align the indices\n",
    "        pd.options.display.max_columns = None\n",
    "        pd.options.display.max_rows    = 50\n",
    "        pd.options.display.min_rows    = 20\n",
    "        meeting_tdocs['Email Count'] = list(emails_per_tdoc['Email Count'])\n",
    "        meeting_tdocs.sort_values(by ='Email Count' , ascending=False, inplace=True)\n",
    "        \n",
    "        # Search for NaNs\n",
    "        nan_entries     = list(meeting_tdocs[meeting_tdocs['AI'].isnull()].index)\n",
    "        # print(nan_entries)\n",
    "        for nan_entry in nan_entries:\n",
    "            try:\n",
    "                email_subject = df[df['subject'].str.contains(\"{0}] \".format(nan_entry))].iloc[0]['subject']\n",
    "                split1 = email_subject.split('] ')\n",
    "                meeting_tdocs.at[nan_entry,'Title'] = split1[-1]\n",
    "                split2 = split1[0].split(', ')[1]\n",
    "                meeting_tdocs.at[nan_entry,'AI'] = split2.replace('AI#','')\n",
    "                # print(emails_for_nans)\n",
    "            except:\n",
    "                pass\n",
    "                # print(\"Error on {0}\".format(nan_entry))\n",
    "        \n",
    "        # display(meeting_tdocs.iloc[0:21,:])\n",
    "        # display(meeting_tdocs)\n",
    "except:\n",
    "    meeting_tdocs = None\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "revisions_file = meeting['revisions_file']\n",
    "with open(revisions_file, 'r') as file:\n",
    "    tdoc_revisions_html = file.read()\n",
    "\n",
    "h = html2text.HTML2Text()\n",
    "# Ignore converting links from HTML\n",
    "h.ignore_links = True\n",
    "tdoc_revisions_text = h.handle(tdoc_revisions_html)\n",
    "tdocs = emails = re.findall(r'S2-[\\d]{7}r[\\d]{2}',tdoc_revisions_text)\n",
    "tdocs = list(set(tdocs))\n",
    "revision_list = [(tdoc[0:-3], tdoc[-2:]) for tdoc in tdocs]\n",
    "\n",
    "df = pd.DataFrame(revision_list, columns =['Tdoc', 'Revisions'])\n",
    "df[\"Revisions\"] = df[[\"Revisions\"]].apply(pd.to_numeric)\n",
    "# display(df)\n",
    "\n",
    "df_per_tdoc = df.groupby(\"Tdoc\")\n",
    "maximums = df_per_tdoc.max()\n",
    "maximums.sort_values(by ='Revisions' , ascending=False, inplace=True)\n",
    "maximums = maximums.reset_index()\n",
    "maximums = maximums.set_index('Tdoc')\n",
    "# display(maximums)\n",
    "\n",
    "meeting_tdocs = pd.concat([meeting_tdocs, maximums], axis=1, sort=False)\n",
    "meeting_tdocs['Email Count'] = meeting_tdocs['Email Count'].fillna(0)\n",
    "meeting_tdocs['Revisions']   = meeting_tdocs['Revisions'].fillna(0)\n",
    "meeting_tdocs['Email Count'] = meeting_tdocs['Email Count'].astype(int)\n",
    "meeting_tdocs['Revisions']   = meeting_tdocs['Revisions'].astype(int)\n",
    "\n",
    "#meeting_tdocs.sort_values(by ='Revisions' , ascending=False, inplace=True)\n",
    "# display(meeting_tdocs.iloc[0:21,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emails/contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = meeting_tdocs.sort_values(by ='Email Count' , ascending=False).iloc[0:(ranking_length+1),:]\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(\n",
    "    meeting_tdocs, \n",
    "    x=\"Email Count\",\n",
    "    labels={\n",
    "        \"Email Count\": \"Number of emails\",\n",
    "        \"count\": \"Number of TDocs\"\n",
    "    },\n",
    "    marginal = 'box')\n",
    "\n",
    "fig.update_yaxes(title_text='')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig_title = \"{0} {1}\".format(title, \"Emails per discussed TDoc\")\n",
    "fig.write_html(os.path.join(plot_folder_html,  fig_title + \".html\"))\n",
    "# fig.write_image(os.path.join(plot_folder_png, fig_title + \".png\"))\n",
    "\n",
    "# print('Mean: {0:.2f} emails/contribution'.format(meeting_tdocs['Email Count'].mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Revisions/contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = meeting_tdocs.sort_values(by ='Revisions' , ascending=False).iloc[0:(ranking_length+1),:]\n",
    "display(result)\n",
    "\n",
    "fig = px.histogram(\n",
    "    meeting_tdocs, \n",
    "    x=\"Revisions\",\n",
    "    labels={\n",
    "        \"Revisions\": \"Number of revisions\",\n",
    "        \"count\": \"Number of TDocs\"\n",
    "    },\n",
    "    marginal = 'box')\n",
    "\n",
    "fig.update_yaxes(title_text='')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig_title = \"{0} {1}\".format(title, \"Revisions per discussed TDoc\")\n",
    "fig.write_html(os.path.join(plot_folder_html,  fig_title + \".html\"))\n",
    "# fig.write_image(os.path.join(plot_folder_png, fig_title + \".png\"))\n",
    "\n",
    "# print('Mean: {0:.2f} revisions/contribution'.format(meeting_tdocs.Revisions.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contribution Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TDocs statistics\n",
    "\n",
    "# Count sources per TDoc\n",
    "tdocs = meeting_tdocs_original.copy()\n",
    "tdocs['Source count'] = tdocs['Source (summary)'].apply(lambda x: len(x.split(',')))\n",
    "tdocs['First source'] = tdocs['Source (summary)'].apply(lambda x: x.split(',')[0])\n",
    "contributors = [e.replace('Contributed by ','') for e in contributor_columns]\n",
    "contributors.append('Others')\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_rows    = 50\n",
    "pd.options.display.min_rows    = 7\n",
    "#display(tdocs)\n",
    "\n",
    "# Make the diagram simpler by plotting only companies\n",
    "contributors_to_ignore_in_diagram = [\n",
    "    'RAN WG1',\n",
    "    'RAN WG2',\n",
    "    'RAN WG3',\n",
    "    'SA WG1',\n",
    "    'SA WG2',\n",
    "    'SA WG3',\n",
    "    'SA WG4',\n",
    "    'SA WG5',\n",
    "    'SA WG6',\n",
    "    'TSG SA',\n",
    "    'TSG CT',\n",
    "    'TSG RAN',\n",
    "    'CT WG1',\n",
    "    'CT WG2',\n",
    "    'CT WG3',\n",
    "    'CT WG4',\n",
    "    'IETF',\n",
    "    'IEEE',\n",
    "    'BBF',\n",
    "    'GSMA'\n",
    "]\n",
    "\n",
    "tdocs_with_multiple_sources = tdocs[tdocs['Source count']>1]\n",
    "\n",
    "contributors_in_meeting = []\n",
    "edge_sizes = {}\n",
    "for idx,contributor in enumerate(contributors):\n",
    "    # Each contributor is a node\n",
    "    contributor_size = tdocs_with_multiple_sources[(tdocs_with_multiple_sources['Contributed by {0}'.format(contributor)]==True)].count()['AI']\n",
    "    if contributor_size > 0:\n",
    "        contributors_in_meeting.append(contributor)\n",
    "        \n",
    "# print('{0} contributors counted in this meeting'.format(len(contributors_in_meeting)))\n",
    "contributors_in_meeting = [e for e in contributors_in_meeting if e not in contributors_to_ignore_in_diagram]\n",
    "# print('{0} contributors counted in this meeting after filtering non-company entities'.format(len(contributors_in_meeting)))\n",
    "        \n",
    "# Generate co-signing matrix\n",
    "# Initialize N (row) x M (columns)\n",
    "N = len(contributors_in_meeting)\n",
    "M = N\n",
    " \n",
    "# using list comprehension \n",
    "# to initializing matrix\n",
    "co_sign_numbers = [ [ 0 for i in range(M) ] for j in range(N) ]\n",
    " \n",
    "# printing result \n",
    "# print(\"Relation matrix after initializing {0}x{1}: \".format(N,M))\n",
    "\n",
    "total_contributors = len(contributors_in_meeting)\n",
    "contributors = {}\n",
    "for idx_1,contributor_1 in enumerate(contributors_in_meeting):\n",
    "    # print('{0}: Checking {1}'.format(idx_1, contributor_1))\n",
    "    contributors[contributor_1] = (tdocs['Contributed by {0}'.format(contributor_1)]==True).sum()\n",
    "    for idx_2,contributor_2 in enumerate(contributors_in_meeting[idx_1+1:total_contributors]):\n",
    "        tdoc_count = int(tdocs_with_multiple_sources[(tdocs_with_multiple_sources['Contributed by {0}'.format(contributor_1)]==True) & (tdocs_with_multiple_sources['Contributed by {0}'.format(contributor_2)]==True)].count()['AI'])\n",
    "        if tdoc_count > 0:\n",
    "            edge_sizes['{0}-{1}'.format(contributor_1,contributor_2)] = tdoc_count\n",
    "            full_idx2 = idx_1+1+idx_2\n",
    "            if idx_1 != full_idx2:\n",
    "                co_sign_numbers[idx_1][full_idx2] = tdoc_count\n",
    "                co_sign_numbers[full_idx2][idx_1] = tdoc_count\n",
    "                # print('  and {0} ({1}): {2}'.format(contributor_2, contributors_in_meeting[full_idx2], tdoc_count))\n",
    "                \n",
    "# print(\"Contributors in meeting ({0})\".format(len(contributors_in_meeting)))\n",
    "# print(contributors_in_meeting)\n",
    "# display(pd.DataFrame(co_sign_numbers))\n",
    "\n",
    "# Number of co-signers per TDoc\n",
    "tdocs_sorted_by_source_count = tdocs.sort_values(by ='Source count' , ascending=False, inplace=False)\n",
    "tdocs_to_display = tdocs_sorted_by_source_count.iloc[0:21,:]\n",
    "tdocs_to_display = tdocs_to_display.loc[:,['AI', 'Type', 'Doc For', 'Title', 'Source', 'Source count']]\n",
    "# display(tdocs_to_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contributions_per_company = pd.DataFrame.from_dict(contributors, orient='index', columns=['contributions'])\n",
    "contributions_per_company.loc[:,'First source'] = tdocs.groupby('First source').count()['AI'].reindex(contributions_per_company.index, fill_value=0)\n",
    "contributions_per_company = contributions_per_company.sort_values(by=['First source', 'contributions'], ascending=False)#.iloc[0:(ranking_length+1),:]\n",
    "\n",
    "# display(contributions_per_company.iloc[1:(ranking_length+1),:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pie_threshold = 0.02\n",
    "total_contributions = contributions_per_company['contributions'].sum()\n",
    "total_first_source_contributions = contributions_per_company['First source'].sum()\n",
    "pie_threshold_contribs = math.floor(total_first_source_contributions * pie_threshold)\n",
    "\n",
    "contributions_per_company['First author percent'] = contributions_per_company['First source'] / total_first_source_contributions\n",
    "contributions_per_company_to_plot = contributions_per_company.loc[contributions_per_company['First author percent'] > pie_threshold,['contributions', 'First source']]\n",
    "\n",
    "extra_row = pd.DataFrame.from_dict(\n",
    "    {\n",
    "        'Others (<{0}%)'.format(pie_threshold*100, pie_threshold_contribs): [\n",
    "            total_contributions - contributions_per_company_to_plot['contributions'].sum(),\n",
    "            total_first_source_contributions - contributions_per_company_to_plot['First source'].sum(),\n",
    "        ]\n",
    "    }, \n",
    "    orient='index',\n",
    "    columns=['contributions', 'First source'])\n",
    "\n",
    "contributions_per_company_to_plot = pd.concat([contributions_per_company_to_plot, extra_row])\n",
    "\n",
    "fig = px.pie(\n",
    "    contributions_per_company_to_plot, \n",
    "    title='TDocs per first author (total {0})'.format(total_first_source_contributions),\n",
    "    names=contributions_per_company_to_plot.index,\n",
    "    values='First source',\n",
    "    labels={\n",
    "        'index': 'Company',\n",
    "        'First source': 'Contributions as first source'\n",
    "    }\n",
    ")\n",
    "\n",
    "fig.update_traces(textposition='inside', textinfo='percent+label')\n",
    "\n",
    "fig.show()\n",
    "\n",
    "fig_title = \"{0} {1}\".format(title, \"First source TDoc distribution\")\n",
    "fig.write_html(os.path.join(plot_folder_html,  fig_title + \".html\"))\n",
    "# fig.write_image(os.path.join(plot_folder_png, fig_title + \".png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
